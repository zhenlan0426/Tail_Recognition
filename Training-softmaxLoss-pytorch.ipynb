{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential,MaxPool2d,Linear,ReLU\n",
    "from functions_pytorch import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchRelu\n",
    "from albumentations_helper import create_transform\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configs ##\n",
    "color = True\n",
    "#shapes = (3,224,224)\n",
    "HalfBatch = 8\n",
    "outDim = 500\n",
    "distanceFun = l2_distance\n",
    "distanceFun_np = l2_distance_np\n",
    "TTASize = 4\n",
    "pct = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.5),RandomBrightness(p=0.5),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=25,scale_limit=0.05,p=1),Cutout(p=0.5)])\n",
    "transform = create_transform(aug)  \n",
    "\n",
    "aug_test = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform_test = create_transform(aug_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(Ids_train,newWhale_train,transform)\n",
    "gen_val = TripletGenerator(Ids_val,newWhale_val,transform_test)        \n",
    "#gen_train = FunctionWrapOverDataset(gen_train,numpy2torch)\n",
    "#gen_val = FunctionWrapOverDataset(gen_val,numpy2torch)\n",
    "train_dl= DataLoader(gen_train,HalfBatch,True,num_workers=3,drop_last=True)\n",
    "valid_dl = DataLoader(gen_val,HalfBatch,False,num_workers=3,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convNet = Sequential(ConvBatchRelu(3,8,5,stride=2),\\\n",
    "#                      ConvBatchRelu(8,16,5,stride=2),\\\n",
    "#                      ConvBatchRelu(16,32,5,stride=2),\\\n",
    "#                      MaxPool2d(2))\n",
    "\n",
    "# fcNet = Sequential(Linear(4608,32),ReLU(True),Linear(32,6))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     fcNet[2].weight.data.zero_()\n",
    "#     fcNet[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "# stn = SpatialTransformerNet(convNet,fcNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base = pretrainedmodels.resnet50()\n",
    "# base = pretrainedmodels.densenet121()\n",
    "# base = fine_tune_pretrainedmodels(base, outDim)\n",
    "# model = Sequential(stn,base).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.densenet121()\n",
    "model = fine_tune_pretrainedmodels(model, outDim).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(HalfBatch,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9363746187210084, val_loss:0.6307057738304138\n",
      "epoch:1, train_loss:0.6406181312263012, val_loss:0.5564051866531372\n",
      "epoch:2, train_loss:0.5792698266804218, val_loss:0.5632326602935791\n",
      "epoch:3, train_loss:0.5105037847280502, val_loss:0.5851256847381592\n",
      "epoch:4, train_loss:0.48829534257650375, val_loss:0.547940731048584\n",
      "Training completed in 149.40972089767456s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ResNet50\n",
    "# set_requires_grad([model[1].layer4,model[1].layer3,model[1].layer2],True)\n",
    "# opt = Adam([\n",
    "#             {\"params\": model[1].layer4.parameters(), \"lr\": 1e-5},\n",
    "#             {\"params\": model[1].layer3.parameters(), \"lr\": 1e-6},\n",
    "#             {\"params\": model[1].layer2.parameters(), \"lr\": 5e-7},\n",
    "#             {\"params\": model[1].last_linear.parameters(), \"lr\": 2e-5},\n",
    "#             {\"params\": model[0].parameters(), \"lr\": 2e-5}\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DenseNet121\n",
    "name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],model), \"lr\": 1e-6},\n",
    "            {\"params\": model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.40156934076547623, val_loss:0.4499461054801941\n",
      "epoch:1, train_loss:0.30486992998719215, val_loss:0.43556976318359375\n",
      "epoch:2, train_loss:0.24957322633862494, val_loss:0.3282415568828583\n",
      "epoch:3, train_loss:0.19049111304283142, val_loss:0.2901590168476105\n",
      "epoch:4, train_loss:0.17467468890547752, val_loss:0.273586630821228\n",
      "Training completed in 258.39065957069397s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk1_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP -> 0.2452690166975881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HalfBatch*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(Ids_train,newWhale_train,transform)\n",
    "gen_val = TripletGenerator(Ids_val,newWhale_val,transform_test)        \n",
    "#gen_train = FunctionWrapOverDataset(gen_train,numpy2torch)\n",
    "#gen_val = FunctionWrapOverDataset(gen_val,numpy2torch)\n",
    "train_dl= DataLoader(gen_train,HalfBatch*2,True,num_workers=3,drop_last=True)\n",
    "valid_dl = DataLoader(gen_val,HalfBatch*2,False,num_workers=3,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(HalfBatch*2,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.2942174540247577, val_loss:0.34849482774734497\n",
      "epoch:1, train_loss:0.2525159327361064, val_loss:0.34434640407562256\n",
      "epoch:2, train_loss:0.23249604321347597, val_loss:0.3346673548221588\n",
      "epoch:3, train_loss:0.23243815917521715, val_loss:0.27159592509269714\n",
      "epoch:4, train_loss:0.1989034809446774, val_loss:0.2889777719974518\n",
      "Training completed in 192.50866723060608s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk2_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP -> 0.37068645640074216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HalfBatch*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(Ids_train,newWhale_train,transform)\n",
    "gen_val = TripletGenerator(Ids_val,newWhale_val,transform_test)        \n",
    "#gen_train = FunctionWrapOverDataset(gen_train,numpy2torch)\n",
    "#gen_val = FunctionWrapOverDataset(gen_val,numpy2torch)\n",
    "train_dl= DataLoader(gen_train,HalfBatch*3,True,num_workers=3,drop_last=True)\n",
    "valid_dl = DataLoader(gen_val,HalfBatch*3,False,num_workers=3,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(HalfBatch*3,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.2527885726079918, val_loss:0.33201363682746887\n",
      "epoch:1, train_loss:0.23088736241110241, val_loss:0.3115643858909607\n",
      "epoch:2, train_loss:0.21344923155489737, val_loss:0.29867690801620483\n",
      "epoch:3, train_loss:0.21914900266207182, val_loss:0.29988279938697815\n",
      "epoch:4, train_loss:0.1989872565139264, val_loss:0.321312814950943\n",
      "Training completed in 174.56020164489746s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk3_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP -> 0.4474953617810761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_gen = PredictGenerator(Ids_train.Imgs.tolist(),transform_test,TTASize, True)\n",
    "pred_val_gen = PredictGenerator(Ids_val.Imgs.tolist(),transform_test,TTASize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = feature_train.reshape(len(pred_train_gen),TTASize,outDim)\n",
    "feature_val = feature_val.reshape(len(pred_val_gen),TTASize,outDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4474953617810761"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
