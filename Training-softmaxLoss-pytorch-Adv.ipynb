{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential,MaxPool2d,Linear,ReLU\n",
    "from functions_pytorch import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchRelu\n",
    "from albumentations_helper import create_transform\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configs ##\n",
    "color = True\n",
    "#shapes = (3,224,224)\n",
    "HalfBatch = 8\n",
    "outDim = 500\n",
    "distanceFun = l2_distance\n",
    "distanceFun_np = l2_distance_np\n",
    "TTASize = 4\n",
    "pct = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine whales with one image with new whale\n",
    "newWhale_train2 = newWhale_train + [i[0] for i in Ids_train.loc[Ids_train.length2 == 1].Imgs.tolist()]\n",
    "Ids_train2 = Ids_train.loc[Ids_train.length2>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.5),RandomBrightness(p=0.5),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=25,scale_limit=0.05,p=1),Cutout(p=0.5)])\n",
    "transform = create_transform(aug)  \n",
    "\n",
    "aug_test = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform_test = create_transform(aug_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "gen_val = TripletGenerator(Ids_val,newWhale_val,transform_test)        \n",
    "#gen_train = FunctionWrapOverDataset(gen_train,numpy2torch)\n",
    "#gen_val = FunctionWrapOverDataset(gen_val,numpy2torch)\n",
    "train_dl= DataLoader(gen_train,HalfBatch,True,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)\n",
    "valid_dl = DataLoader(gen_val,HalfBatch,False,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convNet = Sequential(ConvBatchRelu(3,8,5,stride=2),\\\n",
    "#                      ConvBatchRelu(8,16,5,stride=2),\\\n",
    "#                      ConvBatchRelu(16,32,5,stride=2),\\\n",
    "#                      MaxPool2d(2))\n",
    "\n",
    "# fcNet = Sequential(Linear(4608,32),ReLU(True),Linear(32,6))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     fcNet[2].weight.data.zero_()\n",
    "#     fcNet[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "# stn = SpatialTransformerNet(convNet,fcNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base = pretrainedmodels.resnet50()\n",
    "# base = pretrainedmodels.densenet121()\n",
    "# base = fine_tune_pretrainedmodels(base, outDim)\n",
    "# model = Sequential(stn,base).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.densenet121()\n",
    "model = fine_tune_pretrainedmodels(model, outDim).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(HalfBatch,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.378513602774, val_loss:0.6938920617103577\n",
      "epoch:1, train_loss:1.0786016539472048, val_loss:0.5873348116874695\n",
      "epoch:2, train_loss:0.9780504273993721, val_loss:0.5312209129333496\n",
      "epoch:3, train_loss:0.9467551719621231, val_loss:0.5066378712654114\n",
      "epoch:4, train_loss:0.9106383736097747, val_loss:0.4823993742465973\n",
      "Training completed in 100.12278580665588s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ResNet50\n",
    "# set_requires_grad([model[1].layer4,model[1].layer3,model[1].layer2],True)\n",
    "# opt = Adam([\n",
    "#             {\"params\": model[1].layer4.parameters(), \"lr\": 1e-5},\n",
    "#             {\"params\": model[1].layer3.parameters(), \"lr\": 1e-6},\n",
    "#             {\"params\": model[1].layer2.parameters(), \"lr\": 5e-7},\n",
    "#             {\"params\": model[1].last_linear.parameters(), \"lr\": 2e-5},\n",
    "#             {\"params\": model[0].parameters(), \"lr\": 2e-5}\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DenseNet121\n",
    "name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],model), \"lr\": 1e-6},\n",
    "            {\"params\": model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7538976313067915, val_loss:0.36819979548454285\n",
      "epoch:1, train_loss:0.5972001439194536, val_loss:0.2910773456096649\n",
      "epoch:2, train_loss:0.44702712851551063, val_loss:0.3043462038040161\n",
      "epoch:3, train_loss:0.39378237675447936, val_loss:0.2815174162387848\n",
      "epoch:4, train_loss:0.3634778571320199, val_loss:0.22795656323432922\n",
      "Training completed in 163.14613795280457s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk1_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 50\n",
    "numBatch = 200\n",
    "batchSize = 16\n",
    "maxImg = Ids_train2.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)\n",
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25083487940630794"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.5731608559850787\n",
      "epoch:1, train_loss:1.388969459168898\n",
      "epoch:2, train_loss:1.2489690171564862\n",
      "epoch:3, train_loss:1.1380954024895944\n",
      "epoch:4, train_loss:1.1011318016410525\n",
      "Training completed in 111.29576396942139s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk2_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38537414965986394"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9601198949449049\n",
      "epoch:1, train_loss:0.9712737682250028\n",
      "epoch:2, train_loss:0.880276007974734\n",
      "epoch:3, train_loss:0.8759040593123827\n",
      "epoch:4, train_loss:0.8341019145859395\n",
      "Training completed in 110.96813440322876s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk3_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4405689548546691"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8243550097193223\n",
      "epoch:1, train_loss:0.8108655268865856\n",
      "epoch:2, train_loss:0.7433415876060235\n",
      "epoch:3, train_loss:0.7531034713560115\n",
      "epoch:4, train_loss:0.6718281174048049\n",
      "Training completed in 110.70977807044983s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk4_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5098484848484849"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7204154378485158\n",
      "epoch:1, train_loss:0.7026290195317216\n",
      "epoch:2, train_loss:0.6978385180560618\n",
      "epoch:3, train_loss:0.6413869630810016\n",
      "epoch:4, train_loss:0.6409262851532039\n",
      "Training completed in 110.86532378196716s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5361471861471861"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7350096482722486\n",
      "epoch:1, train_loss:0.6582221756053102\n",
      "epoch:2, train_loss:0.6930301607957955\n",
      "epoch:3, train_loss:0.6240561480730609\n",
      "epoch:4, train_loss:0.6301098224895249\n",
      "Training completed in 111.04898929595947s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5807050092764379"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6281781810554651\n",
      "epoch:1, train_loss:0.5996673433873497\n",
      "epoch:2, train_loss:0.5876219293784574\n",
      "epoch:3, train_loss:0.5490044508882559\n",
      "epoch:4, train_loss:0.5633841182201937\n",
      "Training completed in 110.80002808570862s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk6_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5880488559059988"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6867647228833756\n",
      "epoch:1, train_loss:0.640121043013419\n",
      "epoch:2, train_loss:0.6268996229507232\n",
      "epoch:3, train_loss:0.5960648732432903\n",
      "epoch:4, train_loss:0.6031294748431346\n",
      "Training completed in 111.36775135993958s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk7_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6148886827458256"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6069116929922599\n",
      "epoch:1, train_loss:0.616407717104818\n",
      "epoch:2, train_loss:0.5550617157517235\n",
      "epoch:3, train_loss:0.5776728700663223\n",
      "epoch:4, train_loss:0.5586168837677585\n",
      "Training completed in 111.10607242584229s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6322201607915894"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8013952577618954\n",
      "epoch:1, train_loss:0.7213272161252512\n",
      "epoch:2, train_loss:0.7221795765102886\n",
      "epoch:3, train_loss:0.6801592710076786\n",
      "epoch:4, train_loss:0.6830412920747624\n",
      "Training completed in 111.30374383926392s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6578695114409401"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7194353253707859\n",
      "epoch:1, train_loss:0.7132565244380894\n",
      "epoch:2, train_loss:0.6710567396398777\n",
      "epoch:3, train_loss:0.708072390753389\n",
      "epoch:4, train_loss:0.6433616190171633\n",
      "Training completed in 111.12934875488281s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6651205936920223"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7180752332011858\n",
      "epoch:1, train_loss:0.7042575235697416\n",
      "epoch:2, train_loss:0.680713798097574\n",
      "epoch:3, train_loss:0.6907698249882036\n",
      "epoch:4, train_loss:0.6511370800231975\n",
      "Training completed in 112.12069201469421s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6690012368583796"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax(batchSize,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.6588831537408255\n",
      "epoch:1, train_loss:1.5427104221667096\n",
      "epoch:2, train_loss:1.4602028242225855\n",
      "epoch:3, train_loss:1.4721440682645703\n",
      "epoch:4, train_loss:1.4851462140760787\n",
      "Training completed in 110.97497200965881s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6661564625850339"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
