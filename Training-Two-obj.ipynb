{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential,MaxPool2d,Linear,ReLU\n",
    "from functions_pytorch import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchRelu\n",
    "from albumentations_helper import create_transform\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configs ##\n",
    "color = True\n",
    "#shapes = (3,224,224)\n",
    "HalfBatch = 16\n",
    "outDim = 500\n",
    "n_class = 5004\n",
    "distanceFun = l2_distance\n",
    "distanceFun_np = l2_distance_np\n",
    "TTASize = 4\n",
    "pct = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine whales with one image with new whale\n",
    "newWhale_train2 = newWhale_train + [i[0] for i in Ids_train.loc[Ids_train.length2 == 1].Imgs.tolist()]\n",
    "Ids_train2 = Ids_train.loc[Ids_train.length2>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for adv training\n",
    "k = 10\n",
    "numBatch = 200\n",
    "batchSize = 16\n",
    "maxImg = Ids_train2.shape[0]-1\n",
    "\n",
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)\n",
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.5),RandomBrightness(p=0.5),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=25,scale_limit=0.05,p=1),Cutout(p=0.5)])\n",
    "transform = create_transform(aug)  \n",
    "\n",
    "aug_test = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform_test = create_transform(aug_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_train = TripletGenerator(Ids_train,newWhale_train,transform,p=0.08)\n",
    "# triplet_dl= DataLoader(gen_train,HalfBatch,True,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)\n",
    "gen_train2 = softmaxGenerator(Ids_train,transform)\n",
    "softmax_dl= DataLoader(gen_train2,HalfBatch,True,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.densenet121()\n",
    "model = fine_tune_pretrainedmodels(model, outDim).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and opt\n",
    "checkpoint = torch.load('Models/chk14_softmax')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7392702535559679"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_head = nn.Linear(model.last_linear.in_features,n_class,bias=False).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model = combineModel(basemodel,softmax_head).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first fix the base and fine-tune the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_requires_grad(softmax_model, False)\n",
    "set_requires_grad(softmax_head, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(softmax_head),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_ncls_loss = loss_func_generator_softmax_ncls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.517992871586802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1/5004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:8.552428557322575\n",
      "epoch:1, train_loss:7.506294331489465\n",
      "epoch:2, train_loss:6.27407548060784\n",
      "epoch:3, train_loss:5.173435159218617\n",
      "epoch:4, train_loss:4.180193519745117\n",
      "Training completed in 55.15099024772644s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(5, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:3.3512251468805165\n",
      "epoch:1, train_loss:2.713530243207247\n",
      "epoch:2, train_loss:2.2012481479308543\n",
      "Training completed in 32.968348264694214s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(3, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.799471650750209\n",
      "epoch:1, train_loss:1.4987670462100933\n",
      "epoch:2, train_loss:1.2952542012700667\n",
      "Training completed in 33.062697887420654s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(3, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1025530717884884\n",
      "Training completed in 11.096718788146973s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterate over softmax and triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_requires_grad(softmax_model, True)\n",
    "set_requires_grad(triplet_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8.5\n",
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_triplet = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],triplet_model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],triplet_model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],triplet_model), \"lr\": 1e-6},\n",
    "            {\"params\": triplet_model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_softmax = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],softmax_model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],softmax_model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],softmax_model), \"lr\": 1e-6},\n",
    "            {\"params\": softmax_model.linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9173421550255555\n",
      "Training completed in 33.345388412475586s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1794272028520458\n",
      "Training completed in 39.54643416404724s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7392702535559679"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620284477427335"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk1_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk1_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('Models/chk1_triplet_model')\n",
    "# triplet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# opt_triplet.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# checkpoint = torch.load('Models/chk1_softmax_model')\n",
    "# softmax_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# opt_softmax.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0152618999038239\n",
      "Training completed in 39.425015687942505s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7634027809477769\n",
      "Training completed in 33.31382513046265s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0172637203514903\n",
      "Training completed in 39.62376570701599s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6760807453821867\n",
      "Training completed in 33.42255353927612s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620284477427335"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730055658627086"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk2_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk2_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0130826754729605\n",
      "Training completed in 39.5515878200531s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.60712833253619\n",
      "Training completed in 33.97565770149231s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8980482210878467\n",
      "Training completed in 39.56730794906616s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.5547530082746958\n",
      "Training completed in 33.485716104507446s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9432387741211333\n",
      "Training completed in 39.566426038742065s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.49342067042986554\n",
      "Training completed in 33.392844676971436s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9402216973363376\n",
      "Training completed in 40.291356325149536s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None,clip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.44436025170561594\n",
      "Training completed in 34.421178102493286s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None,clip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730055658627086"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804421768707482"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk3_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk3_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9602008053188116\n",
      "Training completed in 39.59159755706787s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.4137777493168146\n",
      "Training completed in 33.49457621574402s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.931597711732153\n",
      "Training completed in 39.61746287345886s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.3701094229442951\n",
      "Training completed in 33.44179344177246s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8817506249729401\n",
      "Training completed in 39.64719605445862s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.32968752401379436\n",
      "Training completed in 33.62010383605957s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8879198306570939\n",
      "Training completed in 40.27020764350891s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None,clip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.32642006205442625\n",
      "Training completed in 34.49658727645874s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None,clip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7804421768707482"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7854669140383427"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk4_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk4_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the rest is copied over from Training-softmaxLoss-pytorch-Adv-withTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ResNet50\n",
    "# set_requires_grad([model[1].layer4,model[1].layer3,model[1].layer2],True)\n",
    "# opt = Adam([\n",
    "#             {\"params\": model[1].layer4.parameters(), \"lr\": 1e-5},\n",
    "#             {\"params\": model[1].layer3.parameters(), \"lr\": 1e-6},\n",
    "#             {\"params\": model[1].layer2.parameters(), \"lr\": 5e-7},\n",
    "#             {\"params\": model[1].last_linear.parameters(), \"lr\": 2e-5},\n",
    "#             {\"params\": model[0].parameters(), \"lr\": 2e-5}\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DenseNet121\n",
    "name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],model), \"lr\": 1e-6},\n",
    "            {\"params\": model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7810285010787307, val_loss:0.3778223693370819\n",
      "epoch:1, train_loss:0.5369224858780702, val_loss:0.29206743836402893\n",
      "epoch:2, train_loss:0.4689952476062084, val_loss:0.31415751576423645\n",
      "epoch:3, train_loss:0.3900194559348086, val_loss:0.2408030480146408\n",
      "epoch:4, train_loss:0.37403056503889337, val_loss:0.23127534985542297\n",
      "Training completed in 163.73842453956604s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk1_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 50\n",
    "numBatch = 200\n",
    "batchSize = 16\n",
    "maxImg = Ids_train2.shape[0]-1\n",
    "\n",
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)\n",
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24036796536796537"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.6357341796322598\n",
      "epoch:1, train_loss:1.4789364595230812\n",
      "epoch:2, train_loss:1.3506384879513516\n",
      "epoch:3, train_loss:1.3398994163411562\n",
      "epoch:4, train_loss:1.2064544385899612\n",
      "Training completed in 110.71649432182312s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk2_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3641774891774892"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.2777612315582447\n",
      "epoch:1, train_loss:1.042473152524135\n",
      "epoch:2, train_loss:1.053432722560695\n",
      "epoch:3, train_loss:0.9402261529463888\n",
      "epoch:4, train_loss:0.9117436111380494\n",
      "Training completed in 110.93116331100464s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk3_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4340136054421769"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9008529884079115\n",
      "epoch:1, train_loss:0.8060934820461795\n",
      "epoch:2, train_loss:0.8383919769704667\n",
      "epoch:3, train_loss:0.7787562650246699\n",
      "epoch:4, train_loss:0.7128494815503965\n",
      "Training completed in 110.94993877410889s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk4_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49706246134817567"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7866094325328133\n",
      "epoch:1, train_loss:0.7456951266755172\n",
      "epoch:2, train_loss:0.7163024214528949\n",
      "epoch:3, train_loss:0.680116604911825\n",
      "epoch:4, train_loss:0.636626806537636\n",
      "Training completed in 110.68660593032837s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5329313543599258"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8808728531817269\n",
      "epoch:1, train_loss:0.8264410771388825\n",
      "epoch:2, train_loss:0.7651666348260608\n",
      "epoch:3, train_loss:0.642489023628782\n",
      "epoch:4, train_loss:0.6516656506338406\n",
      "Training completed in 113.60318064689636s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5610235003092146"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6887034554787672\n",
      "epoch:1, train_loss:0.6549804205777215\n",
      "epoch:2, train_loss:0.6540592023746563\n",
      "epoch:3, train_loss:0.6092244425757987\n",
      "epoch:4, train_loss:0.6051490222577189\n",
      "Training completed in 111.02671241760254s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk6_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5879870129870131"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9244699263588978\n",
      "epoch:1, train_loss:0.7520761778527271\n",
      "epoch:2, train_loss:0.6808652697039432\n",
      "epoch:3, train_loss:0.6345080832233194\n",
      "epoch:4, train_loss:0.6399718110190064\n",
      "Training completed in 110.97688150405884s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk7_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6138991960420531"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 4\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.14703390246532\n",
      "epoch:1, train_loss:1.0281447813810547\n",
      "epoch:2, train_loss:1.0145563427867785\n",
      "epoch:3, train_loss:0.9966852046101471\n",
      "epoch:4, train_loss:0.9258869370964707\n",
      "Training completed in 111.22468185424805s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6908008658008659"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1533960927216733\n",
      "epoch:1, train_loss:1.0611220960571466\n",
      "epoch:2, train_loss:1.0241561054857702\n",
      "epoch:3, train_loss:1.0516141748330632\n",
      "epoch:4, train_loss:1.01720767399001\n",
      "Training completed in 110.9772777557373s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk9_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6676716141001855"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1138147467472514\n",
      "epoch:1, train_loss:1.0732262225750366\n",
      "epoch:2, train_loss:1.0917892705221646\n",
      "epoch:3, train_loss:1.0086230331105612\n",
      "epoch:4, train_loss:0.9855393247851909\n",
      "Training completed in 111.1889820098877s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk10_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.700278293135436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0715792899737593\n",
      "epoch:1, train_loss:0.9973182217345211\n",
      "epoch:2, train_loss:1.0252600699826016\n",
      "epoch:3, train_loss:0.9855394455008819\n",
      "epoch:4, train_loss:0.9961773318345429\n",
      "Training completed in 111.08159947395325s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk11_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7195887445887447"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0243798535866815\n",
      "epoch:1, train_loss:0.974644305927506\n",
      "epoch:2, train_loss:0.9019275261241881\n",
      "epoch:3, train_loss:0.9820473317891523\n",
      "epoch:4, train_loss:0.9574115609780687\n",
      "Training completed in 111.39126515388489s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk12_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7326530612244897"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0616543284042286\n",
      "epoch:1, train_loss:1.0658719638169138\n",
      "epoch:2, train_loss:0.9775271939693905\n",
      "epoch:3, train_loss:1.0060471941213138\n",
      "epoch:4, train_loss:1.0001072941419205\n",
      "Training completed in 111.2577314376831s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk13_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7370748299319727"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 7\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.914326873307671\n",
      "epoch:1, train_loss:0.9290357761777164\n",
      "epoch:2, train_loss:0.8302613088830573\n",
      "epoch:3, train_loss:0.8555441172233696\n",
      "epoch:4, train_loss:0.833375633210758\n",
      "Training completed in 111.1541588306427s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk13_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
