{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential,MaxPool2d,Linear,ReLU\n",
    "from functions_pytorch import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchRelu\n",
    "from albumentations_helper import create_transform\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configs ##\n",
    "color = True\n",
    "#shapes = (3,224,224)\n",
    "HalfBatch = 16\n",
    "outDim = 500\n",
    "n_class = 5004\n",
    "distanceFun = l2_distance\n",
    "distanceFun_np = l2_distance_np\n",
    "TTASize = 4\n",
    "pct = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine whales with one image with new whale\n",
    "newWhale_train2 = newWhale_train + [i[0] for i in Ids_train.loc[Ids_train.length2 == 1].Imgs.tolist()]\n",
    "Ids_train2 = Ids_train.loc[Ids_train.length2>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for adv training\n",
    "k = 10\n",
    "numBatch = 200\n",
    "batchSize = 16\n",
    "maxImg = Ids_train.shape[0]-1\n",
    "\n",
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)\n",
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.5),RandomBrightness(p=0.5),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=25,scale_limit=0.05,p=1),Cutout(p=0.5)])\n",
    "transform = create_transform(aug)  \n",
    "\n",
    "aug_test = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform_test = create_transform(aug_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_train = TripletGenerator(Ids_train,newWhale_train,transform,p=0.08)\n",
    "# triplet_dl= DataLoader(gen_train,HalfBatch,True,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)\n",
    "gen_train2 = softmaxGenerator(Ids_train,transform)\n",
    "softmax_dl= DataLoader(gen_train2,HalfBatch,True,num_workers=3,drop_last=True,worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.densenet121()\n",
    "model = fine_tune_pretrainedmodels(model, outDim).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and opt\n",
    "checkpoint = torch.load('Models/chk13_softmax')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#opt.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7358534322820037"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "predicts2 = loop_distance(feature_train,feature_train,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train,newWhale_train,transform)\n",
    "triplet_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DenseNet121\n",
    "name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],model), \"lr\": 1e-6},\n",
    "            {\"params\": model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.498046744782\n",
      "epoch:1, train_loss:0.430293626892261\n",
      "epoch:2, train_loss:0.43683309872180986\n",
      "epoch:3, train_loss:0.4200887754559517\n",
      "epoch:4, train_loss:0.42925518767860454\n",
      "Training completed in 110.76845049858093s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456555349412491"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk14_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxImg = Ids_train2.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = model.features\n",
    "triplet_head = model.last_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = combineModel(basemodel,triplet_head).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_head = nn.Linear(model.last_linear.in_features,n_class,bias=False).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model = combineModel(basemodel,softmax_head).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first fix the base and fine-tune the softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_requires_grad(softmax_model, False)\n",
    "set_requires_grad(softmax_head, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(softmax_head),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_ncls_loss = loss_func_generator_softmax_ncls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.517992871586802"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1/5004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:8.553624996772179\n",
      "epoch:1, train_loss:7.491284335270906\n",
      "epoch:2, train_loss:6.240115297146333\n",
      "epoch:3, train_loss:5.120467702547709\n",
      "epoch:4, train_loss:4.11218028037976\n",
      "Training completed in 54.83893299102783s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(5, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:3.292431895549481\n",
      "epoch:1, train_loss:2.632393945486118\n",
      "epoch:2, train_loss:2.1537800662410564\n",
      "Training completed in 32.7993438243866s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(3, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.7630457765398881\n",
      "epoch:1, train_loss:1.462304250170023\n",
      "Training completed in 22.096632480621338s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(2, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.270547329615324\n",
      "Training completed in 11.098731756210327s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterate over softmax and triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_requires_grad(softmax_model, True)\n",
    "set_requires_grad(triplet_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_triplet = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],triplet_model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],triplet_model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],triplet_model), \"lr\": 1e-6},\n",
    "            {\"params\": triplet_model.linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_softmax = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],softmax_model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],softmax_model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],softmax_model), \"lr\": 1e-6},\n",
    "            {\"params\": softmax_model.linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0490098480039682\n",
      "Training completed in 33.49002647399902s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:6.934492647973566\n",
      "Training completed in 40.33090305328369s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:4.169286271913456\n",
      "epoch:1, train_loss:3.397436350421176\n",
      "epoch:2, train_loss:3.009854577278179\n",
      "epoch:3, train_loss:2.677219830249828\n",
      "Training completed in 158.67363739013672s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(4, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:2.5489901975204385\n",
      "epoch:1, train_loss:2.322910188162913\n",
      "epoch:2, train_loss:2.239956478603551\n",
      "epoch:3, train_loss:2.1225674165402606\n",
      "Training completed in 160.9392054080963s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(4, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9582981087076359\n",
      "epoch:1, train_loss:0.7706135513308721\n",
      "Training completed in 67.29729700088501s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(2, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:3.0027510053147384\n",
      "epoch:1, train_loss:2.332282318932111\n",
      "Training completed in 79.64997506141663s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(2, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456555349412491"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564625850340136"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk1_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk1_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "triplet_dl = DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('Models/chk1_triplet_model')\n",
    "triplet_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt_triplet.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "checkpoint = torch.load('Models/chk1_softmax_model')\n",
    "softmax_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt_softmax.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:2.2566009092200647\n",
      "Training completed in 39.651938676834106s\n"
     ]
    }
   ],
   "source": [
    "triplet_model = fit(1, triplet_model, loss_func, opt_triplet, triplet_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7169135524294316\n",
      "Training completed in 34.03325414657593s\n"
     ]
    }
   ],
   "source": [
    "softmax_model = fit(1, softmax_model, softmax_ncls_loss, opt_softmax, softmax_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585961657390228"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP for softmax_model\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "feature_val = predict(softmax_model,pred_val_gen)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,n_class)\n",
    "feature_val_mean = -feature_val.mean(1)\n",
    "predict_softmax = np.array([top_k(x) for x in feature_val_mean])\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-f9a517ad1566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_val_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictGenerator2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIds_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTTASize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfeature_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_train_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeature_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_val_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/utility/pytorch_util.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, dataloader, to_numpy)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/utility/pytorch_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-fede455083de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# validation MAP for triplet_model\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(triplet_model,pred_train_gen)\n",
    "feature_val = predict(triplet_model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': triplet_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_triplet.state_dict(),\n",
    "            }, 'Models/chk2_triplet_model')\n",
    "torch.save({\n",
    "            'model_state_dict': softmax_model.state_dict(),\n",
    "            'optimizer_state_dict': opt_softmax.state_dict(),\n",
    "            }, 'Models/chk2_softmax_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the rest is copied over from Training-softmaxLoss-pytorch-Adv-withTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ResNet50\n",
    "# set_requires_grad([model[1].layer4,model[1].layer3,model[1].layer2],True)\n",
    "# opt = Adam([\n",
    "#             {\"params\": model[1].layer4.parameters(), \"lr\": 1e-5},\n",
    "#             {\"params\": model[1].layer3.parameters(), \"lr\": 1e-6},\n",
    "#             {\"params\": model[1].layer2.parameters(), \"lr\": 5e-7},\n",
    "#             {\"params\": model[1].last_linear.parameters(), \"lr\": 2e-5},\n",
    "#             {\"params\": model[0].parameters(), \"lr\": 2e-5}\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for DenseNet121\n",
    "name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['denseblock4','norm5'],model), \"lr\": 1e-4},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock3','transition3'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['denseblock2','transition2'],model), \"lr\": 1e-6},\n",
    "            {\"params\": model.last_linear.parameters(), \"lr\": 2e-4}\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7810285010787307, val_loss:0.3778223693370819\n",
      "epoch:1, train_loss:0.5369224858780702, val_loss:0.29206743836402893\n",
      "epoch:2, train_loss:0.4689952476062084, val_loss:0.31415751576423645\n",
      "epoch:3, train_loss:0.3900194559348086, val_loss:0.2408030480146408\n",
      "epoch:4, train_loss:0.37403056503889337, val_loss:0.23127534985542297\n",
      "Training completed in 163.73842453956604s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl,lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk1_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "k = 50\n",
    "numBatch = 200\n",
    "batchSize = 16\n",
    "maxImg = Ids_train2.shape[0]-1\n",
    "\n",
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)\n",
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24036796536796537"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.6357341796322598\n",
      "epoch:1, train_loss:1.4789364595230812\n",
      "epoch:2, train_loss:1.3506384879513516\n",
      "epoch:3, train_loss:1.3398994163411562\n",
      "epoch:4, train_loss:1.2064544385899612\n",
      "Training completed in 110.71649432182312s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk2_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3641774891774892"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.2777612315582447\n",
      "epoch:1, train_loss:1.042473152524135\n",
      "epoch:2, train_loss:1.053432722560695\n",
      "epoch:3, train_loss:0.9402261529463888\n",
      "epoch:4, train_loss:0.9117436111380494\n",
      "Training completed in 110.93116331100464s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk3_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4340136054421769"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9008529884079115\n",
      "epoch:1, train_loss:0.8060934820461795\n",
      "epoch:2, train_loss:0.8383919769704667\n",
      "epoch:3, train_loss:0.7787562650246699\n",
      "epoch:4, train_loss:0.7128494815503965\n",
      "Training completed in 110.94993877410889s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk4_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49706246134817567"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.7866094325328133\n",
      "epoch:1, train_loss:0.7456951266755172\n",
      "epoch:2, train_loss:0.7163024214528949\n",
      "epoch:3, train_loss:0.680116604911825\n",
      "epoch:4, train_loss:0.636626806537636\n",
      "Training completed in 110.68660593032837s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5329313543599258"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.8808728531817269\n",
      "epoch:1, train_loss:0.8264410771388825\n",
      "epoch:2, train_loss:0.7651666348260608\n",
      "epoch:3, train_loss:0.642489023628782\n",
      "epoch:4, train_loss:0.6516656506338406\n",
      "Training completed in 113.60318064689636s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk5_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5610235003092146"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.6887034554787672\n",
      "epoch:1, train_loss:0.6549804205777215\n",
      "epoch:2, train_loss:0.6540592023746563\n",
      "epoch:3, train_loss:0.6092244425757987\n",
      "epoch:4, train_loss:0.6051490222577189\n",
      "Training completed in 111.02671241760254s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk6_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5879870129870131"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.9244699263588978\n",
      "epoch:1, train_loss:0.7520761778527271\n",
      "epoch:2, train_loss:0.6808652697039432\n",
      "epoch:3, train_loss:0.6345080832233194\n",
      "epoch:4, train_loss:0.6399718110190064\n",
      "Training completed in 110.97688150405884s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk7_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6138991960420531"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 4\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.14703390246532\n",
      "epoch:1, train_loss:1.0281447813810547\n",
      "epoch:2, train_loss:1.0145563427867785\n",
      "epoch:3, train_loss:0.9966852046101471\n",
      "epoch:4, train_loss:0.9258869370964707\n",
      "Training completed in 111.22468185424805s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk8_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6908008658008659"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1533960927216733\n",
      "epoch:1, train_loss:1.0611220960571466\n",
      "epoch:2, train_loss:1.0241561054857702\n",
      "epoch:3, train_loss:1.0516141748330632\n",
      "epoch:4, train_loss:1.01720767399001\n",
      "Training completed in 110.9772777557373s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk9_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6676716141001855"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.1138147467472514\n",
      "epoch:1, train_loss:1.0732262225750366\n",
      "epoch:2, train_loss:1.0917892705221646\n",
      "epoch:3, train_loss:1.0086230331105612\n",
      "epoch:4, train_loss:0.9855393247851909\n",
      "Training completed in 111.1889820098877s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk10_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.700278293135436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0715792899737593\n",
      "epoch:1, train_loss:0.9973182217345211\n",
      "epoch:2, train_loss:1.0252600699826016\n",
      "epoch:3, train_loss:0.9855394455008819\n",
      "epoch:4, train_loss:0.9961773318345429\n",
      "Training completed in 111.08159947395325s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk11_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7195887445887447"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0243798535866815\n",
      "epoch:1, train_loss:0.974644305927506\n",
      "epoch:2, train_loss:0.9019275261241881\n",
      "epoch:3, train_loss:0.9820473317891523\n",
      "epoch:4, train_loss:0.9574115609780687\n",
      "Training completed in 111.39126515388489s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk12_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7326530612244897"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 6\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:1.0616543284042286\n",
      "epoch:1, train_loss:1.0658719638169138\n",
      "epoch:2, train_loss:0.9775271939693905\n",
      "epoch:3, train_loss:1.0060471941213138\n",
      "epoch:4, train_loss:1.0001072941419205\n",
      "Training completed in 111.2577314376831s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk13_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7370748299319727"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation MAP\n",
    "pred_train_gen = PredictGenerator2(Ids_train.Imgs.tolist(),transform_test,TTASize, 4,True)\n",
    "pred_val_gen = PredictGenerator2(Ids_val.Imgs.tolist(),transform_test,TTASize, 2,True)\n",
    "\n",
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)\n",
    "\n",
    "feature_train = feature_train.reshape(Ids_train.shape[0],TTASize,outDim)\n",
    "feature_val = feature_val.reshape(Ids_val.shape[0],TTASize,outDim)\n",
    "\n",
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)\n",
    "\n",
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.ones((batchSize,batchSize),device='cuda:0') * 7\n",
    "temp[torch.arange(batchSize),torch.arange(batchSize)] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv training\n",
    "feature_train2 = feature_train[Ids_train.length2>1]\n",
    "predicts2 = loop_distance(feature_train2,feature_train2,distanceFun_np,aggFun,returnValue=False,k=k)\n",
    "distDict = {i:[j for j in item.tolist() if i!=j] for i,item in enumerate(predicts2)}\n",
    "batch_sampler = AdvSample(distDict,numBatch,batchSize,maxImg)\n",
    "\n",
    "gen_train = TripletGenerator(Ids_train2,newWhale_train2,transform)\n",
    "train_dl= DataLoader(gen_train,num_workers=3,batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator_softmax_Temp(batchSize,distanceFun,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:0.914326873307671\n",
      "epoch:1, train_loss:0.9290357761777164\n",
      "epoch:2, train_loss:0.8302613088830573\n",
      "epoch:3, train_loss:0.8555441172233696\n",
      "epoch:4, train_loss:0.833375633210758\n",
      "Training completed in 111.1541588306427s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, lossBest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            }, 'Models/chk13_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
