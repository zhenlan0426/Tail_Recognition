{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from functions import margin_loss_fun_factory,DataGenerator,PredictGenerator,\\\n",
    "                        l2_distance_np,top_k,loop_distance,MAP,generate_feature,dot_distance_neg_np\n",
    "import pickle\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "from utility.albumentations_helper import create_transform\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = False\n",
    "#FFA_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_model = load_model('Models/feature_model_DenseNet_greyscale_cross_entropy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_model = load_model('Models/feature_l2_distance_margin_loss_fun_factory(0.1,5).h5', \\\n",
    "#                            custom_objects={'loss': margin_loss_fun_factory(0.1,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform = create_transform(aug)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator(tf.keras.utils.Sequence):\n",
    "    # use all images available and no TTA\n",
    "    def __init__(self, Ids, batchSize):\n",
    "        self.length = [len(sublist) for sublist in Ids]\n",
    "        self.Ids = [item for sublist in Ids for item in sublist] # flatten list of lists, to [w1_img1,w1_img2...,w2_img1,w2_img2...]\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch.'\n",
    "        len_ = len(self.Ids)\n",
    "        return len_//self.batchSize + (1 if len_%self.batchSize>0 else 0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.Ids[index*self.batchSize:(index+1)*self.batchSize]\n",
    "        X = self.__data_generation(indexes)\n",
    "        return X\n",
    "        \n",
    "    def __data_generation(self, indexes):\n",
    "        return np.array([np.load(img) for img in indexes])[:,:,:,np.newaxis]\n",
    "    \n",
    "def generate_feature_test(Ids,batchSize,feature_model):\n",
    "    feature_gen = TestGenerator(Ids if isinstance(Ids,list) else Ids.Imgs.tolist(),batchSize)\n",
    "    feature = feature_model.predict_generator(feature_gen,workers=2,use_multiprocessing=True)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_gen = TestGenerator(Ids_val.Imgs.tolist(),16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = TestGenerator(Ids_train.Imgs.tolist(),16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[7:12] == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_gen)//feature_gen.batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127*feature_gen.batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2035"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feature_gen.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_val=feature_model.predict_generator(feature_gen,workers=2,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train=generate_feature_test(Ids_train,16,feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFuns = [partial(np.quantile,q=pct,axis=(1,2)) for pct in [0.1,0.25,0.5]] + [partial(np.mean,axis=(1,2))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFA_sizes = [4,8]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, {'q': 0.1, 'axis': (1, 2)}, 0.04010513296227582]\n",
      "[4, {'q': 0.25, 'axis': (1, 2)}, 0.033178726035868904]\n",
      "[4, {'q': 0.5, 'axis': (1, 2)}, 0.02694805194805195]\n",
      "[4, {'axis': (1, 2)}, 0.026004947433518864]\n",
      "[8, {'q': 0.1, 'axis': (1, 2)}, 0.03877551020408165]\n",
      "[8, {'q': 0.25, 'axis': (1, 2)}, 0.029359925788497217]\n",
      "[8, {'q': 0.5, 'axis': (1, 2)}, 0.020748299319727888]\n",
      "[8, {'axis': (1, 2)}, 0.02051638837353123]\n"
     ]
    }
   ],
   "source": [
    "for FFA_size in FFA_sizes:\n",
    "    feature_train = generate_feature(Ids_train,transform,FFA_size,color,feature_model)\n",
    "    feature_val = generate_feature(Ids_val,transform,FFA_size,color,feature_model)\n",
    "    for aggFun in aggFuns:\n",
    "        predicts = loop_distance(feature_train,feature_val,dot_distance_neg_np,aggFun)\n",
    "        mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "        labels = Ids_val.Id.map(mapping_dict)\n",
    "        score = MAP(labels,predicts)\n",
    "        print([FFA_size,aggFun.keywords,score])\n",
    "        results.append([FFA_size,aggFun.keywords,score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[4, {'q': 0.1, 'axis': (1, 2)}, 0.04010513296227582]\n",
    "[4, {'q': 0.25, 'axis': (1, 2)}, 0.033178726035868904]\n",
    "[4, {'q': 0.5, 'axis': (1, 2)}, 0.02694805194805195]\n",
    "[4, {'axis': (1, 2)}, 0.026004947433518864]\n",
    "[8, {'q': 0.1, 'axis': (1, 2)}, 0.03877551020408165]\n",
    "[8, {'q': 0.25, 'axis': (1, 2)}, 0.029359925788497217]\n",
    "[8, {'q': 0.5, 'axis': (1, 2)}, 0.020748299319727888]\n",
    "[8, {'axis': (1, 2)}, 0.02051638837353123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
