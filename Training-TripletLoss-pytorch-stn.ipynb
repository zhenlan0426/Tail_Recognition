{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Sequential,MaxPool2d,Linear,ReLU\n",
    "from functions_pytorch import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchRelu\n",
    "from albumentations_helper import create_transform\n",
    "from albumentations import ShiftScaleRotate,Cutout,RandomContrast,RandomBrightness,Compose\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pretrainedmodels\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configs ##\n",
    "color = True\n",
    "#shapes = (3,224,224)\n",
    "HalfBatch = 8\n",
    "margin = -2\n",
    "outDim = 200\n",
    "distanceFun = l2_distance\n",
    "distanceFun_np = l2_distance_np\n",
    "TTASize = 4\n",
    "pct = 0.1\n",
    "multiple = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if color:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df_color.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train_color.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df_color.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val_color.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)\n",
    "else:\n",
    "    with open('/home/will/Desktop/kaggle/Whale/train_df.pkl', 'rb') as f:\n",
    "        Ids_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_train.pkl', 'rb') as f:\n",
    "        newWhale_train = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/val_df.pkl', 'rb') as f:\n",
    "        Ids_val = pickle.load(f)\n",
    "    with open('/home/will/Desktop/kaggle/Whale/new_whale_val.pkl', 'rb') as f:\n",
    "        newWhale_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = Compose([RandomContrast(p=0.5),RandomBrightness(p=0.5),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=25,scale_limit=0.05,p=1),Cutout(p=0.5)])\n",
    "transform = create_transform(aug)  \n",
    "\n",
    "aug_test = Compose([RandomContrast(p=0.2),RandomBrightness(p=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.03,rotate_limit=15,scale_limit=0.02,p=1)])\n",
    "transform_test = create_transform(aug_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(Ids_train,newWhale_train,transform)\n",
    "gen_val = TripletGenerator(Ids_val,newWhale_val,transform_test)        \n",
    "#gen_train = FunctionWrapOverDataset(gen_train,numpy2torch)\n",
    "#gen_val = FunctionWrapOverDataset(gen_val,numpy2torch)\n",
    "train_dl= DataLoader(gen_train,HalfBatch,True,num_workers=3,drop_last=True)\n",
    "valid_dl = DataLoader(gen_val,HalfBatch,False,num_workers=3,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = Sequential(ConvBatchRelu(3,8,5,stride=2),\\\n",
    "                     ConvBatchRelu(8,16,5,stride=2),\\\n",
    "                     ConvBatchRelu(16,32,5,stride=2),\\\n",
    "                     ConvBatchRelu(32,64,5,stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcNet = Sequential(Linear(7744,32),ReLU(True),Linear(32,6*multiple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = SpatialTransformerNetMutiple(loc,fcNet,multiple,[3, 112, 112])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pretrainedmodels.resnet18()\n",
    "base = fine_tune_pretrainedmodels(base, outDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STN_multiple_model(stn,base).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = loss_func_generator(HalfBatch,margin,distanceFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=1e-4)\n",
    "#opt = SGD(trainable_parameter(model),lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.2952669328123331, val_loss:-0.549985945224762\n",
      "epoch:1, train_loss:-0.5167314027965069, val_loss:-0.5381356477737427\n",
      "epoch:2, train_loss:-0.656345286154747, val_loss:-0.23699015378952026\n",
      "epoch:3, train_loss:-0.49013974902629853, val_loss:-0.8242770433425903\n",
      "epoch:4, train_loss:-0.7187960035681724, val_loss:-0.7648609280586243\n",
      "Training completed in 212.52335715293884s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-0.7536704321503639, val_loss:-1.0333362817764282\n",
      "epoch:1, train_loss:-0.8645521814107895, val_loss:-0.9286816716194153\n",
      "epoch:2, train_loss:-0.8533955804347992, val_loss:-0.8994772434234619\n",
      "epoch:3, train_loss:-0.8535406195878983, val_loss:-1.1930184364318848\n",
      "epoch:4, train_loss:-1.01813995013237, val_loss:-1.0756570100784302\n",
      "Training completed in 212.13031125068665s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ResNet50\n",
    "# set_requires_grad([model[1].layer4,model[1].layer3,model[1].layer2],True)\n",
    "# opt = Adam([\n",
    "#             {\"params\": model[1].layer4.parameters(), \"lr\": 1e-5},\n",
    "#             {\"params\": model[1].layer3.parameters(), \"lr\": 1e-6},\n",
    "#             {\"params\": model[1].layer2.parameters(), \"lr\": 5e-7},\n",
    "#             {\"params\": model[1].last_linear.parameters(), \"lr\": 2e-5},\n",
    "#             {\"params\": model[0].parameters(), \"lr\": 2e-5}\n",
    "#             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_requires_grad(model,True)\n",
    "#name_list = ['denseblock3','transition3','denseblock4','norm5']\n",
    "#set_requires_grad_paraList(gather_parameter_nameList(name_list,model),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam([\n",
    "            {\"params\": gather_parameter_nameList(['layer4'],model), \"lr\": 5e-5},\n",
    "            {\"params\": gather_parameter_nameList(['layer3'],model), \"lr\": 2e-5},\n",
    "            {\"params\": gather_parameter_nameList(['layer2'],model), \"lr\": 1e-5},\n",
    "            {\"params\": gather_parameter_nameList(['layer1'],model), \"lr\": 5e-6},\n",
    "            {\"params\": model.convNet.conv1.parameters(), \"lr\": 2e-6},\n",
    "            {\"params\": model.convNet.bn1.parameters(), \"lr\": 2e-6},\n",
    "            ],lr=8e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-1.1085381864786148, val_loss:-1.1494746208190918\n",
      "epoch:1, train_loss:-1.2792052606582642, val_loss:-1.181570291519165\n",
      "epoch:2, train_loss:-1.2663943541526794, val_loss:-1.2974693775177002\n",
      "epoch:3, train_loss:-1.3377004085302353, val_loss:-1.3113305568695068\n",
      "epoch:4, train_loss:-1.3569880262374878, val_loss:-1.3325304985046387\n",
      "Training completed in 293.33615016937256s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:-1.3693908285617828, val_loss:-1.3452659845352173\n",
      "epoch:1, train_loss:-1.407889396905899, val_loss:-1.2048245668411255\n",
      "epoch:2, train_loss:-1.45262935962677, val_loss:-1.2281945943832397\n",
      "epoch:3, train_loss:-1.4333325175285339, val_loss:-1.2810242176055908\n",
      "epoch:4, train_loss:-1.4772603550434114, val_loss:-1.353670358657837\n",
      "Training completed in 292.55577206611633s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_gen = PredictGenerator(Ids_train.Imgs.tolist(),transform_test,TTASize, True)\n",
    "pred_val_gen = PredictGenerator(Ids_val.Imgs.tolist(),transform_test,TTASize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = predict(model,pred_train_gen)\n",
    "feature_val = predict(model,pred_val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = feature_train.reshape(len(pred_train_gen),TTASize,outDim)\n",
    "feature_val = feature_val.reshape(len(pred_val_gen),TTASize,outDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFun = partial(np.quantile,q=pct,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = loop_distance(feature_train,feature_val,distanceFun_np,aggFun,returnValue=False,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip(Ids_train.Id.values,Ids_train.index.values))\n",
    "labels = Ids_val.Id.map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12482993197278912"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP(labels,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
